{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5e81f6a5",
   "metadata": {},
   "source": [
    "### Given a topic research the latest news"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7ba322a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "from utils import utils , llms\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a1502a2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The early life and exceptional talent of Magnus Carlsen.',\n",
       " \"Carlsen's early exposure to puzzles, chess, and his incredible memory.\",\n",
       " \"Carlsen's rapid growth and early victories in the chess world.\",\n",
       " \"Carlsen's unique style and approach to chess.\",\n",
       " \"Carlsen's journey to becoming the World Chess Champion.\",\n",
       " \"An overview of Carlsen's career after 2006 and his personal life.\",\n",
       " 'Reminding viewers to like, subscribe, and highlighting the AI operation of the channel.',\n",
       " \"Recapping Carlsen's achievements and expressing gratitude to the viewers.\"]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "utils.set_prefix(\"../output/magnuscarlsen\")\n",
    "scenes = utils.get_scenes()\n",
    "# Extract lines starting with \"[Scene\"\n",
    "scene_lines = [s.description for s in scenes]\n",
    "scene_lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d6c69e6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"id2label\"]` will be overriden.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import torch\n",
    "from diffusers import StableDiffusionPipeline\n",
    "\n",
    "pipeline = StableDiffusionPipeline.from_pretrained(\"SG161222/Realistic_Vision_V2.0\", torch_dtype=torch.float16)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d016f806",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = pipeline.to(\"cuda\")\n",
    "pipeline.enable_xformers_memory_efficient_attention()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1b58b568",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[diffusers.schedulers.scheduling_ddim.DDIMScheduler,\n",
       " diffusers.schedulers.scheduling_heun_discrete.HeunDiscreteScheduler,\n",
       " diffusers.schedulers.scheduling_lms_discrete.LMSDiscreteScheduler,\n",
       " diffusers.schedulers.scheduling_deis_multistep.DEISMultistepScheduler,\n",
       " diffusers.schedulers.scheduling_pndm.PNDMScheduler,\n",
       " diffusers.schedulers.scheduling_k_dpm_2_ancestral_discrete.KDPM2AncestralDiscreteScheduler,\n",
       " diffusers.schedulers.scheduling_euler_discrete.EulerDiscreteScheduler,\n",
       " diffusers.schedulers.scheduling_k_dpm_2_discrete.KDPM2DiscreteScheduler,\n",
       " diffusers.schedulers.scheduling_euler_ancestral_discrete.EulerAncestralDiscreteScheduler,\n",
       " diffusers.schedulers.scheduling_ddpm.DDPMScheduler,\n",
       " diffusers.utils.dummy_torch_and_torchsde_objects.DPMSolverSDEScheduler,\n",
       " diffusers.schedulers.scheduling_dpmsolver_singlestep.DPMSolverSinglestepScheduler,\n",
       " diffusers.schedulers.scheduling_dpmsolver_multistep.DPMSolverMultistepScheduler,\n",
       " diffusers.schedulers.scheduling_unipc_multistep.UniPCMultistepScheduler]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.scheduler.compatibles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b73d9bbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from diffusers import DPMSolverMultistepScheduler\n",
    "\n",
    "pipeline.scheduler = DPMSolverMultistepScheduler.from_config(pipeline.scheduler.config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "07844b3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_prompt = \"\"\"\n",
    "(high detailed skin:1.2, high quality, reportage, journalism),\n",
    "8k uhd, dslr, soft lighting, film grain, Fujifilm XT3\n",
    "\"\"\"\n",
    "\n",
    "negative_prompt=\"\"\"\n",
    "((text:1.5, deformed iris, deformed pupils, deformed hands, nsfw)),\n",
    "((semi-realistic, cgi, 3d, render, sketch, cartoon, drawing, anime:1.4)),\n",
    "close up, cropped, out of frame, worst quality, low quality, jpeg artifacts, ugly, duplicate,\n",
    "morbid, mutilated, extra fingers, mutated hands, poorly drawn hands, poorly drawn face, mutation,\n",
    "deformed, blurry, burns, dehydrated, bad anatomy, bad proportions, extra limbs, cloned face, disfigured,\n",
    "gross proportions, malformed limbs, missing arms, missing legs, extra arms, extra legs,\n",
    "fused fingers, too many fingers, long neck\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "45bddd26",
   "metadata": {},
   "outputs": [],
   "source": [
    "## LLM To create thumbnail prompt from scenes\n",
    "from langchain import LLMChain\n",
    "from langchain.prompts.chat import (ChatPromptTemplate, SystemMessagePromptTemplate, AIMessagePromptTemplate, HumanMessagePromptTemplate)\n",
    "\n",
    "template=\"\"\"\n",
    "You are a YouTube thumbnail artist, the human will provide you with a script for the episode.\n",
    "Your task is to create a prompt that the human will use to generate the thumbnail.\n",
    "\n",
    "The keywords you use in your prompt generation are very important, so choose them wisely.\n",
    "The prompt must describe an enticing thumbnail with interesting colors matching the general mood of the human provided\n",
    "script.\n",
    "\n",
    "Format your response as a JSON array of objects as defined below, you will always generate 10 prompts.\n",
    "\n",
    "an example element for a script about the Titanic :\n",
    "{{\n",
    "  \"prompt\": \"The Titanic ship, in the bottom of the ocean, with sea stuff growing on it, Narrator's face in scuba gear doing thumbs up overlayed on the real image\"\n",
    "}}\n",
    "\"\"\"\n",
    "system_message_prompt = SystemMessagePromptTemplate.from_template(template)\n",
    "human_message_prompt = HumanMessagePromptTemplate.from_template(\"{text}\")\n",
    "\n",
    "chat_prompt = ChatPromptTemplate.from_messages([system_message_prompt, human_message_prompt])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6a16eafa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[\\n  {\\n    \"prompt\": \"A young Magnus Carlsen intensely focused on a chessboard, with the words \\'The Prodigy\\' above him in bold letters. Include a sepia filter for a nostalgic mood.\"\\n  },\\n  {\\n    \"prompt\": \"A collage of Magnus Carlsen as a child solving puzzles, playing with Lego, and learning chess from his father. Overlay the images with a vibrant, energetic color scheme.\"\\n  },\\n  {\\n    \"prompt\": \"Magnus Carlsen shaking hands with Grandmaster Simen Agdestein, with a rocket taking off in the background symbolizing his skyrocketing chess rating. Use dynamic colors and lines for a sense of motion.\"\\n  },\\n  {\\n    \"prompt\": \"Magnus Carlsen sitting at a chessboard, with ghostly chess pieces floating around him to represent different openings. Use a mix of mysterious blues and vibrant oranges.\"\\n  },\\n  {\\n    \"prompt\": \"Magnus Carlsen holding a World Chess Champion trophy, with a montage of opponents like Anand, Karjakin, and Caruana in the background. Use a golden glow to signify triumph.\"\\n  },\\n  {\\n    \"prompt\": \"A book opening to reveal various milestones in Magnus Carlsen\\'s career post-2006, with chess pieces as bookmarks. Use warm, inviting colors to convey the depth of his story.\"\\n  },\\n  {\\n    \"prompt\": \"A futuristic AI robot hand clicking a mouse with the text \\'Like & Subscribe\\', and a chessboard in the background to symbolize the AI-operated channel. Use sleek silvers and cool blues.\"\\n  },\\n  {\\n    \"prompt\": \"Magnus Carlsen standing tall as a king on a life-sized chessboard with other historical greats as chess pieces. Use regal colors such as deep purples and royal golds.\"\\n  },\\n  {\\n    \"prompt\": \"Magnus Carlsen\\'s face fading into a chessboard, with key achievements and dates overlayed on the board. Use black and white for the chessboard with contrasting bright text colors.\"\\n  },\\n  {\\n    \"prompt\": \"A silhouette of Magnus Carlsen waving, with scenes from his career and a heartwarming \\'Thank you\\' message. Use soft, warm colors to create an emotional and thankful ambiance.\"\\n  }\\n]'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain = LLMChain(llm=llms.RevGPTLLM(model=\"gpt-4\"), prompt=chat_prompt)\n",
    "prompts_raw = chain.run(open(utils.SCRIPT).read())\n",
    "prompts_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "78a44865",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "50e8954f6dbc440199a924b714b3a7ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d281d04df6924aa4ae29033c6c54fb27",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (85 > 77). Running this sequence through the model will result in indexing errors\n",
      "The following part of your input was truncated because CLIP can only handle sequences up to 77 tokens: ['lighting, film grain, fujifilm xt 3']\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "78e1f28cf6b14c5a8e74810950886107",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e88b65ea6c349eb8d94175bf512a540",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following part of your input was truncated because CLIP can only handle sequences up to 77 tokens: ['grain, fujifilm xt 3']\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b6139b997c034c53ad8fddc0bc056078",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following part of your input was truncated because CLIP can only handle sequences up to 77 tokens: [', fujifilm xt 3']\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa557db675964091a3b76ee823e109a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following part of your input was truncated because CLIP can only handle sequences up to 77 tokens: [', fujifilm xt 3']\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b31d4765a9848638e33252b5ff014f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following part of your input was truncated because CLIP can only handle sequences up to 77 tokens: ['3']\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a9ef8fe9cbab498e8ce418aba46b0251",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following part of your input was truncated because CLIP can only handle sequences up to 77 tokens: ['3']\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f13de054c8e042c6b001d8e15650bedd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed28122e242142ee9a5d0bc7eb91ab80",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "guidance_scale        = 0.7\n",
    "num_inference_steps   = 30\n",
    "num_images_per_prompt = 2\n",
    "image_height = 512\n",
    "image_width = 768\n",
    "\n",
    "for i,line in enumerate(json.loads(prompts_raw)):\n",
    "    prompt = line\n",
    "    images = pipeline(\n",
    "        prompt=\"{} {}\".format(prompt, positive_prompt),\n",
    "        negative_prompt=negative_prompt,\n",
    "        height=image_height,\n",
    "        width=image_width,\n",
    "        num_images_per_prompt=num_images_per_prompt,\n",
    "        num_inference_steps=num_inference_steps,\n",
    "        #guidance_scale=guidance_scale,\n",
    "    ).images\n",
    "        \n",
    "    for j,image in enumerate(images):\n",
    "        image.save(\"{}/thumbnails/thumbnail_{}_{}.jpg\".format(utils.PATH_PREFIX, i+1, j+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "54e964b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Free GPU memory for upscaler\n",
    "del pipeline\n",
    "del images\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "35ef9617",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "text_encoder/model.safetensors not found\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "from diffusers import StableDiffusionUpscalePipeline\n",
    "\n",
    "import torch\n",
    "\n",
    "pipeline = StableDiffusionUpscalePipeline.from_pretrained(\n",
    "    \"stabilityai/stable-diffusion-x4-upscaler\",\n",
    "    revision=\"fp16\",\n",
    "    torch_dtype=torch.float16\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b8bfedca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xformers.ops import MemoryEfficientAttentionFlashAttentionOp\n",
    "\n",
    "pipeline = pipeline.to(\"cuda\")\n",
    "pipeline.enable_xformers_memory_efficient_attention(attention_op=MemoryEfficientAttentionFlashAttentionOp)\n",
    "# Workaround for not accepting attention shape using VAE for Flash Attention\n",
    "pipeline.vae.enable_xformers_memory_efficient_attention(attention_op=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1ae09c66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[diffusers.schedulers.scheduling_k_dpm_2_discrete.KDPM2DiscreteScheduler,\n",
       " diffusers.schedulers.scheduling_dpmsolver_multistep.DPMSolverMultistepScheduler,\n",
       " diffusers.schedulers.scheduling_ddim.DDIMScheduler,\n",
       " diffusers.schedulers.scheduling_lms_discrete.LMSDiscreteScheduler,\n",
       " diffusers.schedulers.scheduling_ddpm.DDPMScheduler,\n",
       " diffusers.schedulers.scheduling_pndm.PNDMScheduler,\n",
       " diffusers.schedulers.scheduling_dpmsolver_singlestep.DPMSolverSinglestepScheduler,\n",
       " diffusers.schedulers.scheduling_deis_multistep.DEISMultistepScheduler,\n",
       " diffusers.schedulers.scheduling_unipc_multistep.UniPCMultistepScheduler,\n",
       " diffusers.utils.dummy_torch_and_torchsde_objects.DPMSolverSDEScheduler,\n",
       " diffusers.schedulers.scheduling_euler_discrete.EulerDiscreteScheduler,\n",
       " diffusers.schedulers.scheduling_k_dpm_2_ancestral_discrete.KDPM2AncestralDiscreteScheduler,\n",
       " diffusers.schedulers.scheduling_euler_ancestral_discrete.EulerAncestralDiscreteScheduler,\n",
       " diffusers.schedulers.scheduling_heun_discrete.HeunDiscreteScheduler]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.scheduler.compatibles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c580e249",
   "metadata": {},
   "outputs": [],
   "source": [
    "from diffusers import DPMSolverMultistepScheduler\n",
    "\n",
    "pipeline.scheduler = DPMSolverMultistepScheduler.from_config(pipeline.scheduler.config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8ce36e39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7abfcd5e1d5d4235843f97598c38ab5e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "16a41a2458c0442bba7a479d8f7cb38f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "13f3dc81701244c9b1d0bdbb00f1d45c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd791bbbff874fb996ce625fceb23d69",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "64653cbf6a524829af994f634e9b8205",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "541e2f41ddbc4a21b48f0f7bd0b2c629",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "53745c50970242b6916bbdd7aeece57b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f8031a708b86419e8f7d4d545ac9853a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "59b31ce562af456dbac359bc25e6b6b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ab6f9fe48d94502a8662fb3c68b5185",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "501c8a8c2a054d368c5482ab0237233a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "003d652951714a30838764482c9879c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "037624c8f35d481184c6c574f4e009d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "94151037c5a946b0b9317cf8a529b701",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "118990165e9446e99765485cdbcdc0ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f7a415ab24d41dfb45598188e7017d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae16af3e732c4cdd9f0fcb3aaf312a4a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b4b1502a2e94e51b2ec761991fe35af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e8b1ae4c6e794cb8b28fe7e7ec9815a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d27101cdae6342d48499c498b2ec1ebb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6027f83d397a40ef987366feacb0d63c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d0bb55717a0242cfa10795b95f129c7f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f375b5d778304a9cb170d840e001a029",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "36b840a258ed4850988c5c973fd46446",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f5f51c76f0f4481e90f153c57fe72a71",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "28aeac74e23b44d6938c17600d0371e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b5b6fab26e14425947852129021328e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "05ae712663734a5cacd04e201f3b9b41",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d3227b32e3b24f40bb311c0d42e46caf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "09e4cf9491614562bafae0b1b5a6bc34",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d154daf01824ca2a133db44a7f15b66",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "92f33f7a8fad48a289d31f83b1e90903",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f94b70992b1d4b4d88200f6f00492391",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a2b7134e2514b26955058dd05cf03c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "464c2f263f0c405eaf0a2d5a9d74ec88",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "148d12467267464b908355521920c715",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1bfb3724c6094f9fbad64e6e6acef8e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "42166e0a5cf84f6db287593c201f836c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d832ef11e13a4bbba31f20165709ae08",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b0acadb77ca4ffaa70b119439081d6f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "guidance_scale        = 0.7\n",
    "num_inference_steps   = 20\n",
    "num_images_per_prompt = 1\n",
    "n = 5\n",
    "\n",
    "for i,prompt in enumerate(scene_lines):\n",
    "    for j in range(1,n+1):\n",
    "        low_res_image = Image.open(\"outputs/robertson/scene_{}_{}.png\".format(i+1,j)).convert(\"RGB\")\n",
    "        low_res_image = low_res_image.resize((256,256))\n",
    "\n",
    "        image = pipeline(\n",
    "            prompt=\"{} {}\".format(prompt, positive_prompt),\n",
    "            negative_prompt=negative_prompt,\n",
    "            image=low_res_image,\n",
    "            num_images_per_prompt=num_images_per_prompt,\n",
    "            num_inference_steps=num_inference_steps,\n",
    "            #guidance_scale=guidance_scale,    \n",
    "        ).images[0]\n",
    "\n",
    "        image.save(\"outputs/robertson/scene_{}_{}_upscaled.png\".format(i+1,j))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bca0c18",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
