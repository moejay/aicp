{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5e81f6a5",
   "metadata": {},
   "source": [
    "### Given a topic research the latest news"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ba322a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d67ae36",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import utilsk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1502a2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.SCRIPT = \"outputs/robertson/script.yaml\"\n",
    "scenes = utils.get_scenes()\n",
    "# Extract lines starting with \"[Scene\"\n",
    "scene_lines = [s.description for s in scenes]\n",
    "scene_lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6c69e6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from diffusers import StableDiffusionPipeline\n",
    "\n",
    "pipeline = StableDiffusionPipeline.from_pretrained(\n",
    "    \"SG161222/Realistic_Vision_V2.0\", torch_dtype=torch.float16\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d016f806",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = pipeline.to(\"cuda\")\n",
    "pipeline.enable_xformers_memory_efficient_attention()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b58b568",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline.scheduler.compatibles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b73d9bbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from diffusers import DPMSolverMultistepScheduler\n",
    "\n",
    "pipeline.scheduler = DPMSolverMultistepScheduler.from_config(pipeline.scheduler.config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07844b3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_prompt = \"\"\"\n",
    "(high detailed skin:1.2, high quality, reportage, journalism),\n",
    "8k uhd, dslr, soft lighting, film grain, Fujifilm XT3\n",
    "\"\"\"\n",
    "\n",
    "negative_prompt = \"\"\"\n",
    "((text:1.5, deformed iris, deformed pupils, deformed hands, nsfw)),\n",
    "((semi-realistic, cgi, 3d, render, sketch, cartoon, drawing, anime:1.4)),\n",
    "close up, cropped, out of frame, worst quality, low quality, jpeg artifacts, ugly, duplicate,\n",
    "morbid, mutilated, extra fingers, mutated hands, poorly drawn hands, poorly drawn face, mutation,\n",
    "deformed, blurry, burns, dehydrated, bad anatomy, bad proportions, extra limbs, cloned face, disfigured,\n",
    "gross proportions, malformed limbs, missing arms, missing legs, extra arms, extra legs,\n",
    "fused fingers, too many fingers, long neck\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78a44865",
   "metadata": {},
   "outputs": [],
   "source": [
    "guidance_scale = 0.7\n",
    "num_inference_steps = 50\n",
    "num_images_per_prompt = 5\n",
    "image_height = 512\n",
    "image_width = 768\n",
    "\n",
    "for i, line in enumerate(scene_lines):\n",
    "    prompt = line\n",
    "    images = pipeline(\n",
    "        prompt=\"{} {}\".format(prompt, positive_prompt),\n",
    "        negative_prompt=negative_prompt,\n",
    "        height=image_height,\n",
    "        width=image_width,\n",
    "        num_images_per_prompt=num_images_per_prompt,\n",
    "        num_inference_steps=num_inference_steps,\n",
    "        # guidance_scale=guidance_scale,\n",
    "    ).images\n",
    "\n",
    "    for j, image in enumerate(images):\n",
    "        image.save(\"outputs/robertson/scene_{}_{}.png\".format(i + 1, j + 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54e964b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Free GPU memory for upscaler\n",
    "del pipeline\n",
    "del images\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35ef9617",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "from diffusers import StableDiffusionUpscalePipeline\n",
    "\n",
    "import torch\n",
    "\n",
    "pipeline = StableDiffusionUpscalePipeline.from_pretrained(\n",
    "    \"stabilityai/stable-diffusion-x4-upscaler\",\n",
    "    revision=\"fp16\",\n",
    "    torch_dtype=torch.float16,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8bfedca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xformers.ops import MemoryEfficientAttentionFlashAttentionOp\n",
    "\n",
    "pipeline = pipeline.to(\"cuda\")\n",
    "pipeline.enable_xformers_memory_efficient_attention(\n",
    "    attention_op=MemoryEfficientAttentionFlashAttentionOp\n",
    ")\n",
    "# Workaround for not accepting attention shape using VAE for Flash Attention\n",
    "pipeline.vae.enable_xformers_memory_efficient_attention(attention_op=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ae09c66",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline.scheduler.compatibles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c580e249",
   "metadata": {},
   "outputs": [],
   "source": [
    "from diffusers import DPMSolverMultistepScheduler\n",
    "\n",
    "pipeline.scheduler = DPMSolverMultistepScheduler.from_config(pipeline.scheduler.config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ce36e39",
   "metadata": {},
   "outputs": [],
   "source": [
    "guidance_scale = 0.7\n",
    "num_inference_steps = 20\n",
    "num_images_per_prompt = 1\n",
    "n = 5\n",
    "\n",
    "for i, prompt in enumerate(scene_lines):\n",
    "    for j in range(1, n + 1):\n",
    "        low_res_image = Image.open(\n",
    "            \"outputs/robertson/scene_{}_{}.png\".format(i + 1, j)\n",
    "        ).convert(\"RGB\")\n",
    "        low_res_image = low_res_image.resize((256, 256))\n",
    "\n",
    "        image = pipeline(\n",
    "            prompt=\"{} {}\".format(prompt, positive_prompt),\n",
    "            negative_prompt=negative_prompt,\n",
    "            image=low_res_image,\n",
    "            num_images_per_prompt=num_images_per_prompt,\n",
    "            num_inference_steps=num_inference_steps,\n",
    "            # guidance_scale=guidance_scale,\n",
    "        ).images[0]\n",
    "\n",
    "        image.save(\"outputs/robertson/scene_{}_{}_upscaled.png\".format(i + 1, j))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc5e2ced",
   "metadata": {},
   "source": [
    "## LORAs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2888c262",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "from IPython.display import display, Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aa393e95",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import image_gen\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fbd8ced8",
   "metadata": {},
   "outputs": [],
   "source": [
    "sd_model = \"SG161222/Realistic_Vision_V3.0\"\n",
    "#sd_model = \"Lykon/dreamshaper\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d863fdfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from safetensors.torch import load_file\n",
    "from diffusers import StableDiffusionPipeline, DPMSolverMultistepScheduler\n",
    "from xformers.ops import MemoryEfficientAttentionFlashAttentionOp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6ba9f520",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c8f312daa8724343880a4e1dac83bebe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading pipeline components...:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pipeline = StableDiffusionPipeline.from_pretrained(sd_model, torch_dtype=torch.float16, safety_checker=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bee80536",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline.scheduler = DPMSolverMultistepScheduler.from_config(\n",
    "    pipeline.scheduler.config, use_karras_sigmas=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "92291b4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline.load_lora_weights(\"../loras\", weight_name=\"ACTOR_Heather.safetensors\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b6e952d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StableDiffusionPipeline {\n",
       "  \"_class_name\": \"StableDiffusionPipeline\",\n",
       "  \"_diffusers_version\": \"0.19.3\",\n",
       "  \"_name_or_path\": \"SG161222/Realistic_Vision_V3.0\",\n",
       "  \"feature_extractor\": [\n",
       "    null,\n",
       "    null\n",
       "  ],\n",
       "  \"requires_safety_checker\": null,\n",
       "  \"safety_checker\": [\n",
       "    null,\n",
       "    null\n",
       "  ],\n",
       "  \"scheduler\": [\n",
       "    \"diffusers\",\n",
       "    \"DPMSolverMultistepScheduler\"\n",
       "  ],\n",
       "  \"text_encoder\": [\n",
       "    \"transformers\",\n",
       "    \"CLIPTextModel\"\n",
       "  ],\n",
       "  \"tokenizer\": [\n",
       "    \"transformers\",\n",
       "    \"CLIPTokenizer\"\n",
       "  ],\n",
       "  \"unet\": [\n",
       "    \"diffusers\",\n",
       "    \"UNet2DConditionModel\"\n",
       "  ],\n",
       "  \"vae\": [\n",
       "    \"diffusers\",\n",
       "    \"AutoencoderKL\"\n",
       "  ]\n",
       "}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c7a87803",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline.enable_attention_slicing()\n",
    "pipeline.enable_vae_slicing()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b68cbef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline.enable_xformers_memory_efficient_attention()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "175e9edc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4cb7157f8d69450f9a47e106cf1f37a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "prompt = \"ACTOR_Heather in a forest, wearing green pantsuit, high quality\"\n",
    "negative_prompt = (\"(low quality, worst quality:1.4), (bad anatomy), (inaccurate limb:1.2), low resolution\"\n",
    "                   \"bad composition, inaccurate eyes, extra digit, deformed face, fewer digits, (extra arms:1.2), large breasts\")\n",
    "\n",
    "images = pipeline(prompt=prompt, \n",
    "    negative_prompt=negative_prompt, \n",
    "    width=512, \n",
    "    height=512, \n",
    "    num_inference_steps=30, \n",
    "    num_images_per_prompt=4,\n",
    "    generator=torch.manual_seed(0)\n",
    ").images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0617944",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(*images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26e60e42",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
